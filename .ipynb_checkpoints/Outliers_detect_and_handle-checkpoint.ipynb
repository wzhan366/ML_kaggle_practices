{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/how-to-identify-outliers-in-your-data/\n",
    "\n",
    "# How to Identify Outliers in your Data\n",
    "by Jason Brownlee on December 31, 2013 in Machine Learning Process\n",
    "Tweet   Share \n",
    "Bojan Miletic asked a question about outlier detection in datasets when working with machine learning algorithms. This post is in answer to his question.\n",
    "\n",
    "If you have a question about machine learning, sign-up to the newsletter and reply to an email or use the contact form and ask, I will answer your question and may even turn it into a blog post.\n",
    "\n",
    "## Outliers\n",
    "Many machine learning algorithms are sensitive to the range and distribution of attribute values in the input data. Outliers in input data can skew and mislead the training process of machine learning algorithms resulting in longer training times, less accurate models and ultimately poorer results.\n",
    "\n",
    "\n",
    "\n",
    "Even before predictive models are prepared on training data, outliers can result in misleading representations and in turn misleading interpretations of collected data. Outliers can skew the summary distribution of attribute values in descriptive statistics like mean and standard deviation and in plots such as histograms and scatterplots, compressing the body of the data.\n",
    "\n",
    "Finally, outliers can represent examples of data instances that are relevant to the problem such as anomalies in the case of fraud detection and computer security.\n",
    "\n",
    "## Outlier Modeling\n",
    "Outliers are extreme values that fall a long way outside of the other observations. For example, in a normal distribution, outliers may be values on the tails of the distribution.\n",
    "\n",
    "The process of identifying outliers has many names in data mining and machine learning such as outlier mining, outlier modeling and novelty detection and anomaly detection.\n",
    "\n",
    "In his book Outlier Analysis (affiliate link), Aggarwal provides a useful taxonomy of outlier detection methods, as follows:\n",
    "\n",
    "Extreme Value Analysis: Determine the statistical tails of the underlying distribution of the data. For example, statistical methods like the z-scores on univariate data.\n",
    "Probabilistic and Statistical Models: Determine unlikely instances from a probabilistic model of the data. For example, gaussian mixture models optimized using expectation-maximization.\n",
    "Linear Models: Projection methods that model the data into lower dimensions using linear correlations. For example, principle component analysis and data with large residual errors may be outliers.\n",
    "Proximity-based Models: Data instances that are isolated from the mass of the data as determined by cluster, density or nearest neighbor analysis.\n",
    "Information Theoretic Models: Outliers are detected as data instances that increase the complexity (minimum code length) of the dataset.\n",
    "High-Dimensional Outlier Detection: Methods that search subspaces for outliers give the breakdown of distance based measures in higher dimensions (curse of dimensionality).\n",
    "Aggarwal comments that the interpretability of an outlier model is critically important. Context or rationale is required around decisions why a specific data instance is or is not an outlier.\n",
    "\n",
    "In his contributing chapter to Data Mining and Knowledge Discovery Handbook (affiliate link), Irad Ben-Gal proposes a taxonomy of outlier models as univariate or multivariate and parametric and nonparametric. This is a useful way to structure methods based on what is known about the data. For example:\n",
    "\n",
    "Are you considered with outliers in one or more than one attributes (univariate or multivariate methods)?\n",
    "Can you assume a statistical distribution from which the observations were sampled or not (parametric or nonparametric)?\n",
    "Get Started\n",
    "There are many methods and much research put into outlier detection. Start by making some assumptions and design experiments where you can clearly observe the effects of the those assumptions against some performance or accuracy measure.\n",
    "\n",
    "I recommend working through a stepped process from extreme value analysis, proximity methods and projection methods.\n",
    "\n",
    "## Extreme Value Analysis\n",
    "You do not need to know advanced statistical methods to look for, analyze and filter out outliers from your data. Start out simple with extreme value analysis.\n",
    "\n",
    "Focus on univariate methods\n",
    "Visualize the data using scatterplots, histograms and box and whisker plots and look for extreme values\n",
    "Assume a distribution (Gaussian) and look for values more than 2 or 3 standard deviations from the mean or 1.5 times from the first or third quartile\n",
    "Filter out outliers candidate from training dataset and assess your models performance\n",
    "## Proximity Methods\n",
    "Once you have explore simpler extreme value methods, consider moving onto proximity-based methods.\n",
    "\n",
    "Use clustering methods to identify the natural clusters in the data (such as the k-means algorithm)\n",
    "Identify and mark the cluster centroids\n",
    "Identify data instances that are a fixed distance or percentage distance from cluster centroids\n",
    "Filter out outliers candidate from training dataset and assess your models performance\n",
    "## Projection Methods\n",
    "Projection methods are relatively simple to apply and quickly highlight extraneous values.\n",
    "\n",
    "Use projection methods to summarize your data to two dimensions (such as PCA, SOM or Sammon’s mapping)\n",
    "Visualize the mapping and identify outliers by hand\n",
    "Use proximity measures from projected values or codebook vectors to identify outliers\n",
    "Filter out outliers candidate from training dataset and assess your models performance\n",
    "## Methods Robust to Outliers\n",
    "An alternative strategy is to move to models that are robust to outliers. There are robust forms of regression that minimize the median least square errors rather than mean (so-called robust regression), but are more computationally intensive. There are also methods like decision trees that are robust to outliers.\n",
    "\n",
    "You could spot check some methods that are robust to outliers. If there are significant model accuracy benefits then there may be an opportunity to model and filter out outliers from your training data.\n",
    "\n",
    "Resources\n",
    "There are a lot of webpages that discuss outlier detection, but I recommend reading through a good book on the subject, something more authoritative. Even looking through introductory books on machine learning and data mining won’t be that useful to you. For a classical treatment of outliers by statisticians, check out:\n",
    "\n",
    "Robust Regression and Outlier Detection (affiliate link) by Rousseeuw and Leroy published in 2003\n",
    "Outliers in Statistical Data (affiliate link) by Barnett and Lewis, published in 1994\n",
    "Identification of Outliers (affiliate link) a monograph by Hawkins published in 1980\n",
    "For a modern treatment of outliers by data mining community, see:\n",
    "\n",
    "Outlier Analysis (affiliate link) by Aggarwal, published in 2013\n",
    "Chapter 7 by Irad Ben-Gal in Data Mining and Knowledge Discovery Handbook (affiliate link) edited by Maimon and Rokach, published in 2010"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/how-to-use-statistics-to-identify-outliers-in-data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are Outliers?\n",
    "An outlier is an observation that is unlike the other observations.\n",
    "\n",
    "It is rare, or distinct, or does not fit in some way.\n",
    "\n",
    "Outliers can have many causes, such as:\n",
    "\n",
    "Measurement or input error.\n",
    "Data corruption.\n",
    "True outlier observation (e.g. Michael Jordan in basketball).\n",
    "There is no precise way to define and identify outliers in general because of the specifics of each dataset. Instead, you, or a domain expert, must interpret the raw observations and decide whether a value is an outlier or not.\n",
    "\n",
    "Nevertheless, we can use statistical methods to identify observations that appear to be rare or unlikely given the available data.\n",
    "\n",
    "This does not mean that the values identified are outliers and should be removed. But, the tools described in this tutorial can be helpful in shedding light on rare events that may require a second look.\n",
    "\n",
    "A good tip is to consider plotting the identified outlier values, perhaps in the context of non-outlier values to see if there are any systematic relationship or pattern to the outliers. If there is, perhaps they are not outliers and can be explained, or perhaps the outliers themselves can be identified more systematically.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset\n",
    "Before we look at outlier identification methods, let’s define a dataset we can use to test the methods.\n",
    "\n",
    "We will generate a population 10,000 random numbers drawn from a Gaussian distribution with a mean of 50 and a standard deviation of 5.\n",
    "\n",
    "Numbers drawn from a Gaussian distribution will have outliers. That is, by virtue of the distribution itself, there will be a few values that will be a long way from the mean, rare values that we can identify as outliers.\n",
    "\n",
    "We will use the randn() function to generate random Gaussian values with a mean of 0 and a standard deviation of 1, then multiply the results by our own standard deviation and add the mean to shift the values into the preferred range.\n",
    "\n",
    "The pseudorandom number generator is seeded to ensure that we get the same sample of numbers each time the code is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean=50.049 stdv=4.994\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# generate gaussian data\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate univariate observations\n",
    "data = 5 * randn(10000) + 50\n",
    "# summarize\n",
    "print('mean=%.3f stdv=%.3f' % (mean(data), std(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Deviation Method\n",
    "If we know that the distribution of values in the sample is Gaussian or Gaussian-like, we can use the standard deviation of the sample as a cut-off for identifying outliers.\n",
    "\n",
    "The Gaussian distribution has the property that the standard deviation from the mean can be used to reliably summarize the percentage of values in the sample.\n",
    "\n",
    "For example, within one standard deviation of the mean will cover 68% of the data.\n",
    "\n",
    "So, if the mean is 50 and the standard deviation is 5, as in the test dataset above, then all data in the sample between 45 and 55 will account for about 68% of the data sample. We can cover more of the data sample if we expand the range as follows:\n",
    "\n",
    "1 Standard Deviation from the Mean: 68%\n",
    "2 Standard Deviations from the Mean: 95%\n",
    "3 Standard Deviations from the Mean: 99.7%\n",
    "A value that falls outside of 3 standard deviations is part of the distribution, but it is an unlikely or rare event at approximately 1 in 370 samples.\n",
    "\n",
    "Three standard deviations from the mean is a common cut-off in practice for identifying outliers in a Gaussian or Gaussian-like distribution. For smaller samples of data, perhaps a value of 2 standard deviations (95%) can be used, and for larger samples, perhaps a value of 4 standard deviations (99.9%) can be used.\n",
    "\n",
    "Let’s make this concrete with a worked example.\n",
    "\n",
    "Sometimes, the data is standardized first (e.g. to a Z-score with zero mean and unit variance) so that the outlier detection can be performed using standard Z-score cut-off values. This is a convenience and is not required in general, and we will perform the calculations in the original scale of the data here to make things clear.\n",
    "\n",
    "We can calculate the mean and standard deviation of a given sample, then calculate the cut-off for identifying outliers as more than 3 standard deviations from the mean.\n",
    "\n",
    "\n",
    "### calculate summary statistics\n",
    "data_mean, data_std = mean(data), std(data)\n",
    "### identify outliers\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate summary statistics\n",
    "data_mean, data_std = mean(data), std(data)\n",
    "# identify outliers\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then identify outliers as those examples that fall outside of the defined lower and upper limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify outliers\n",
    "outliers = [x for x in data if x < lower or x > upper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can put this all together with our sample dataset prepared in the previous section.\n",
    "\n",
    "The complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified outliers: 29\n",
      "Non-outlier observations: 9971\n"
     ]
    }
   ],
   "source": [
    "# identify outliers with standard deviation\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate univariate observations\n",
    "data = 5 * randn(10000) + 50\n",
    "# calculate summary statistics\n",
    "data_mean, data_std = mean(data), std(data)\n",
    "# identify outliers\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "# identify outliers\n",
    "outliers = [x for x in data if x < lower or x > upper]\n",
    "print('Identified outliers: %d' % len(outliers))\n",
    "# remove outliers\n",
    "outliers_removed = [x for x in data if x >= lower and x <= upper]\n",
    "print('Non-outlier observations: %d' % len(outliers_removed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example will first print the number of identified outliers and then the number of observations that are not outliers, demonstrating how to identify and filter out outliers respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have only talked about univariate data with a Gaussian distribution, e.g. a single variable. You can use the same approach if you have multivariate data, e.g. data with multiple variables, each with a different Gaussian distribution.\n",
    "\n",
    "You can imagine bounds in two dimensions that would define an ellipse if you have two variables. Observations that fall outside of the ellipse would be considered outliers. In three dimensions, this would be an ellipsoid, and so on into higher dimensions.\n",
    "\n",
    "Alternately, if you knew more about the domain, perhaps an outlier may be identified by exceeding the limits on one or a subset of the data dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interquartile Range Method\n",
    "Not all data is normal or normal enough to treat it as being drawn from a Gaussian distribution.\n",
    "\n",
    "A good statistic for summarizing a non-Gaussian distribution sample of data is the Interquartile Range, or IQR for short.\n",
    "\n",
    "The IQR is calculated as the difference between the 75th and the 25th percentiles of the data and defines the box in a box and whisker plot.\n",
    "\n",
    "Remember that percentiles can be calculated by sorting the observations and selecting values at specific indices. The 50th percentile is the middle value, or the average of the two middle values for an even number of examples. If we had 10,000 samples, then the 50th percentile would be the average of the 5000th and 5001st values.\n",
    "\n",
    "We refer to the percentiles as quartiles (“quart” meaning 4) because the data is divided into four groups via the 25th, 50th and 75th values.\n",
    "\n",
    "The IQR defines the middle 50% of the data, or the body of the data.\n",
    "\n",
    "The IQR can be used to identify outliers by defining limits on the sample values that are a factor k of the IQR below the 25th percentile or above the 75th percentile. The common value for the factor k is the value 1.5. A factor k of 3 or more can be used to identify values that are extreme outliers or “far outs” when described in the context of box and whisker plots.\n",
    "\n",
    "On a box and whisker plot, these limits are drawn as fences on the whiskers (or the lines) that are drawn from the box. Values that fall outside of these values are drawn as dots.\n",
    "\n",
    "We can calculate the percentiles of a dataset using the percentile() NumPy function that takes the dataset and specification of the desired percentile. The IQR can then be calculated as the difference between the 75th and 25th percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate interquartile range\n",
    "from numpy import percentile\n",
    "q25, q75 = percentile(data, 25), percentile(data, 75)\n",
    "iqr = q75 - q25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then calculate the cutoff for outliers as 1.5 times the IQR and subtract this cut-off from the 25th percentile and add it to the 75th percentile to give the actual limits on the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the outlier cutoff\n",
    "cut_off = iqr * 1.5\n",
    "lower, upper = q25 - cut_off, q75 + cut_off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use these limits to identify the outlier values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify outliers\n",
    "outliers = [x for x in data if x < lower or x > upper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the limits to filter out the outliers from the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_removed = [x for x in data if x > lower and x < upper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tie all of this together and demonstrate the procedure on the test dataset.\n",
    "\n",
    "The complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentiles: 25th=46.685, 75th=53.359, IQR=6.674\n",
      "Identified outliers: 81\n",
      "Non-outlier observations: 9919\n"
     ]
    }
   ],
   "source": [
    "# identify outliers with interquartile range\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import percentile\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate univariate observations\n",
    "data = 5 * randn(10000) + 50\n",
    "# calculate interquartile range\n",
    "q25, q75 = percentile(data, 25), percentile(data, 75)\n",
    "iqr = q75 - q25\n",
    "print('Percentiles: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25, q75, iqr))\n",
    "# calculate the outlier cutoff\n",
    "cut_off = iqr * 1.5\n",
    "lower, upper = q25 - cut_off, q75 + cut_off\n",
    "# identify outliers\n",
    "outliers = [x for x in data if x < lower or x > upper]\n",
    "print('Identified outliers: %d' % len(outliers))\n",
    "# remove outliers\n",
    "outliers_removed = [x for x in data if x >= lower and x <= upper]\n",
    "print('Non-outlier observations: %d' % len(outliers_removed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach can be used for multivariate data by calculating the limits on each variable in the dataset in turn, and taking outliers as observations that fall outside of the rectangle or hyper-rectangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
